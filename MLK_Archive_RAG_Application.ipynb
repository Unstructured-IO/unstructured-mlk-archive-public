{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f7c0a68",
   "metadata": {},
   "source": [
    "# Making History Accessible: Exploring the MLK Assassination Declassified Records\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Dr. Martin Luther King Jr.'s legacy is one of courage, justice, and transformation. The recently declassified records surrounding his assassination (now hosted by the National Archives) are a vital part of the historical record. These documents provide important insights into a pivotal moment in American history and the civil rights movement.\n",
    "\n",
    "In this notebook, we'll explore how modern AI and data processing technologies can make these historical documents more accessible and searchable, enabling researchers, educators, journalists, and the public to engage with this important material.\n",
    "\n",
    "## Historical Context and Significance\n",
    "\n",
    "Dr. Martin Luther King Jr. was assassinated on April 4, 1968, in Memphis, Tennessee. His assassination had profound impacts on the civil rights movement and the nation as a whole.\n",
    "\n",
    "The declassified records surrounding his assassination provide valuable insights into:\n",
    "\n",
    "- The investigation conducted by various government agencies\n",
    "- The evidence collected and analyzed\n",
    "- The broader historical and social context of the time\n",
    "\n",
    "By making these records more accessible through modern AI and data processing technologies, we can help ensure that this important historical information is preserved and available for future generations to study and learn from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac06a3c5",
   "metadata": {},
   "source": [
    "## The Unstructured Platform and Document Processing Workflow\n",
    "\n",
    "Before we build our question-answering application, let's understand the data processing workflow that makes this possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fff273",
   "metadata": {},
   "source": [
    "### How the MLK Records Were Prepared for Search\n",
    "\n",
    "> *Note: The steps below were completed prior to this notebook. You do not need to rerun them—they're included here to explain how the records were made searchable.*\n",
    "\n",
    "The declassified MLK assassination records were processed using the **Unstructured platform** in a multi-step ETL pipeline to make them AI-ready and searchable:\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 1: Document Ingestion into Amazon S3**\n",
    "\n",
    "- Original documents—including PDFs, images, and other file types—were streamed from the National Archives to **Amazon S3**, providing secure and scalable cloud storage.\n",
    "   - National Archives: https://www.archives.gov/research/mlk\n",
    "   - AWS Files: http://example-transformations-mlk-archive.s3-website-us-east-1.amazonaws.com/\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 2: Document Processing with Unstructured**\n",
    "\n",
    "The Unstructured platform processed each document through a series of enrichment steps:\n",
    "\n",
    "1. **VLM Partitioning**  \n",
    "    Vision language models (VLMs) segmented each document into meaningful sections, preserving layout and context. Because most documents were scanned images of typed pages—making OCR challenging—VLMs were chosen for partitioning. Claude 3.7 Sonnet was used as the VLM provider.\n",
    "\n",
    "2. **Title-Based Chunking**  \n",
    "   Documents were split into semantically coherent chunks using structural cues (like section headers) to improve context retention. A \"Chunk by Title\" chunking strategy with contextual chunking was used. The chunking parameters were:\n",
    "   ```\n",
    "   {\n",
    "   \"contextual_chunking\": true,\n",
    "   \"combine_text_under_n_characters\": 3000,\n",
    "   \"include_original_elements\": true,\n",
    "   \"max_characters\": 5500,\n",
    "   \"multipage_sections\": true,\n",
    "   \"new_after_n_characters\": 3500,\n",
    "   \"overlap\": 350,\n",
    "   \"overlap_all\": true\n",
    "   }\n",
    "   ```\n",
    "\n",
    "3. **Named Entity Recognition (NER)**  \n",
    "   Entities such as people, organizations, locations, and dates were extracted to enhance downstream filtering and relevance. OpenAI GPT-4o was used with the default NER prompt. For more information about NER, please see our documentation: https://docs.unstructured.io/ui/enriching/ner\n",
    "\n",
    "4. **Vector Embedding**  \n",
    "   Each chunk was embedded using OpenAI's `text-embedding-3-large` model (3072 dims), enabling semantic similarity search.\n",
    "\n",
    "This end-to-end pipeline transformed the raw historical documents into a searchable, structured knowledge base, optimized for natural language queries and intelligent retrieval. Unstructured made it possible to transform 243,496 pages of grainy text in a single day.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 3: Indexing in Elasticsearch**\n",
    "\n",
    "- The enriched document chunks—with metadata and vector embeddings—were indexed into **Elasticsearch**, enabling:\n",
    "  - Fast full-text and semantic (vector) search  \n",
    "  - Metadata-based filtering and sorting  \n",
    "  - Scalable querying across large document sets\n",
    "\n",
    "Access to this database is available using the following credentials:\n",
    "```\n",
    "ELASTICSEARCH_HOSTS: \"https://mlk-archive-public.es.eastus.azure.elastic-cloud.com\"\n",
    "ELASTICSEARCH_API_KEY: \"S0I5ak5aZ0JwcE44OWFmcEpBb3M6dTlpYnVQbk9Ub2dKNk15LUpkT0JwUQ==\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Results\n",
    "The processed output of the ETL is available via an ElasticSearch database as explained in this Jupyter Notebook, or a JSONL copy of the processed data is available for you to download and use for your own research:\n",
    "- https://example-transformations-mlk-archive.s3.us-east-1.amazonaws.com/transformed-data/mlk-archive-public.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0caff6d",
   "metadata": {},
   "source": [
    "### Benefits of This Approach\n",
    "\n",
    "This workflow offers several advantages for historical document collections:\n",
    "\n",
    "- **Preservation of Context**: The intelligent partitioning and chunking preserve the document's original structure and context.\n",
    "\n",
    "- **Enhanced Searchability**: Both keyword and semantic search capabilities make it easier to find relevant information.\n",
    "\n",
    "- **Metadata Enrichment**: Named entity recognition adds valuable metadata that can be used for filtering and organization.\n",
    "\n",
    "- **Accessibility**: Makes historical documents more accessible to researchers, educators, and the public.\n",
    "\n",
    "- **AI-Readiness**: The processed data is ready for use in advanced AI applications, including RAG (Retrieval-Augmented Generation) systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733e9de5",
   "metadata": {},
   "source": [
    "## Building a Question-Answering System for the MLK Assassination Records\n",
    "\n",
    "Now, let's build a Retrieval-Augmented Generation (RAG) application using LangChain that will allow us to query the ElasticSearch database to ask questions about the MLK assassination declassified records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5866711d",
   "metadata": {},
   "source": [
    "### Setting Up the Environment\n",
    "\n",
    "First, let's install the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ee5727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./mlk_scraper_env/lib/python3.13/site-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-elasticsearch in ./mlk_scraper_env/lib/python3.13/site-packages (0.3.2)\n",
      "Requirement already satisfied: langchain-openai in ./mlk_scraper_env/lib/python3.13/site-packages (0.3.28)\n",
      "Requirement already satisfied: langchain_anthropic in ./mlk_scraper_env/lib/python3.13/site-packages (0.3.17)\n",
      "Requirement already satisfied: python-dotenv in ./mlk_scraper_env/lib/python3.13/site-packages (1.1.1)\n",
      "Requirement already satisfied: elasticsearch in ./mlk_scraper_env/lib/python3.13/site-packages (8.18.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain) (0.3.71)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain) (0.4.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./mlk_scraper_env/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./mlk_scraper_env/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./mlk_scraper_env/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./mlk_scraper_env/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./mlk_scraper_env/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./mlk_scraper_env/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./mlk_scraper_env/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./mlk_scraper_env/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
      "Requirement already satisfied: elastic-transport<9,>=8.15.1 in ./mlk_scraper_env/lib/python3.13/site-packages (from elasticsearch) (8.17.1)\n",
      "Requirement already satisfied: python-dateutil in ./mlk_scraper_env/lib/python3.13/site-packages (from elasticsearch) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1 in ./mlk_scraper_env/lib/python3.13/site-packages (from elasticsearch[vectorstore-mmr]<9.0.0,>=8.13.1->langchain-elasticsearch) (2.3.1)\n",
      "Requirement already satisfied: simsimd>=3 in ./mlk_scraper_env/lib/python3.13/site-packages (from elasticsearch[vectorstore-mmr]<9.0.0,>=8.13.1->langchain-elasticsearch) (6.5.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain-openai) (1.97.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./mlk_scraper_env/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./mlk_scraper_env/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./mlk_scraper_env/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./mlk_scraper_env/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in ./mlk_scraper_env/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./mlk_scraper_env/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in ./mlk_scraper_env/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./mlk_scraper_env/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./mlk_scraper_env/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: anthropic<1,>=0.57.0 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain_anthropic) (0.58.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./mlk_scraper_env/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./mlk_scraper_env/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./mlk_scraper_env/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: six>=1.5 in ./mlk_scraper_env/lib/python3.13/site-packages (from python-dateutil->elasticsearch) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install langchain langchain-elasticsearch langchain-openai langchain_anthropic python-dotenv elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bebd681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9fd9cf",
   "metadata": {},
   "source": [
    "### Connecting to Elasticsearch\n",
    "\n",
    "We'll connect to the Elasticsearch instance where the processed MLK assassination records are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162fec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_elasticsearch.vectorstores import ElasticsearchStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Use the read-only ELASTICSEARCH API Key\n",
    "ELASTICSEARCH_HOSTS = \"https://mlk-archive-public.es.eastus.azure.elastic-cloud.com\"\n",
    "ELASTICSEARCH_API_KEY=\"S0I5ak5aZ0JwcE44OWFmcEpBb3M6dTlpYnVQbk9Ub2dKNk15LUpkT0JwUQ==\"\n",
    "\n",
    "# API key for OpenAI (used for both embeddings and LLM)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"your-openai-api-key\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "# Connect to public proxy (no API key required)\n",
    "es_store = ElasticsearchStore(\n",
    "    es_url=ELASTICSEARCH_HOSTS,\n",
    "    index_name=\"mlk-archive-public\",\n",
    "    embedding=embeddings,\n",
    "    vector_query_field=\"embeddings\",\n",
    "    query_field=\"text\",\n",
    "    es_api_key=ELASTICSEARCH_API_KEY,\n",
    ")\n",
    "\n",
    "\n",
    "# Create a retriever\n",
    "retriever = es_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}  # Retrieve top 5 most relevant documents\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38078b53",
   "metadata": {},
   "source": [
    "### Creating a Prompt\n",
    "\n",
    "When dealing with sensitive historical material like the MLK assassination records, it's important to create a prompt that:\n",
    "\n",
    "1. Respects the historical significance of the material\n",
    "2. Provides accurate information based on the documents\n",
    "3. Acknowledges the limitations of the available information\n",
    "4. Avoids speculation beyond what's in the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb1cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom prompt template\n",
    "template = \"\"\"\n",
    "You are a respectful and knowledgeable assistant helping to provide information about the declassified MLK assassination records.\n",
    "\n",
    "These documents are an important part of American history and the civil rights movement. Please treat this subject with the appropriate gravity and respect.\n",
    "\n",
    "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df7f60f",
   "metadata": {},
   "source": [
    "### Building the RAG Application\n",
    "\n",
    "Now we'll create a Retrieval-Augmented Generation (RAG) application that:\n",
    "\n",
    "1. Takes a user question about the MLK assassination records\n",
    "2. Retrieves relevant document chunks from Elasticsearch\n",
    "3. Uses the retrieved context to generate an accurate, respectful answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced95e3b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OpenAI GPT-4o model for RAG responses\n"
     ]
    }
   ],
   "source": [
    "# Always use OpenAI for the LLM\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o\",\n",
    "    temperature=0.1,  # Low temperature for more factual responses\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")\n",
    "print(\"Using OpenAI GPT-4o model for RAG responses\")\n",
    "\n",
    "# Create the RAG chain\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT},\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbecbd0",
   "metadata": {},
   "source": [
    "### Interactive Question Answering\n",
    "\n",
    "Let's create a simple interface to ask questions about the MLK assassination records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9649f4a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def ask_question(question):\n",
    "    \"\"\"\n",
    "    Ask a question about the MLK assassination records and get an answer\n",
    "    with source citations.\n",
    "    \"\"\"\n",
    "    result = rag_chain({\"query\": question})\n",
    "    \n",
    "    # Extract the answer and source documents\n",
    "    answer = result[\"result\"]\n",
    "    source_docs = result[\"source_documents\"]\n",
    "    \n",
    "    # Print the answer\n",
    "    print(\"Answer:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(answer)\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Print source information\n",
    "    print(\"\\nSources:\")\n",
    "    print(\"-\" * 80)\n",
    "    for i, doc in enumerate(source_docs):\n",
    "        print(f\"Source {i+1}:\")\n",
    "        print(f\"  Text: {doc.page_content[:150]}...\")\n",
    "        if hasattr(doc, 'metadata') and doc.metadata:\n",
    "            if 'filename' in doc.metadata:\n",
    "                print(f\"  Document: {doc.metadata['filename']}\")\n",
    "            if 'page_number' in doc.metadata:\n",
    "                print(f\"  Page: {doc.metadata['page_number']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220736c6",
   "metadata": {},
   "source": [
    "### Example Questions\n",
    "\n",
    "Here are some example questions you might ask about the MLK assassination records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c4fde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "--------------------------------------------------------------------------------\n",
      "The investigation of Dr. Martin Luther King Jr.'s assassination involved multiple agencies, including:\n",
      "\n",
      "1. The Federal Bureau of Investigation (FBI) - Conducted the primary investigation into the assassination and reviewed extensive files and materials related to both the murder investigation and pre-assassination surveillance of Dr. King.\n",
      "\n",
      "2. The Memphis Police Department (MPD) - Involved in the immediate response and evidence collection at the crime scene.\n",
      "\n",
      "3. The Department of Justice - Oversaw the investigation and reviewed the FBI's performance.\n",
      "\n",
      "Additionally, other agencies were canvassed to determine if they had any intelligence or counterintelligence information related to Dr. King, including:\n",
      "\n",
      "- The Defense Department\n",
      "- The State Department\n",
      "- The U.S. Information Agency\n",
      "- The Central Intelligence Agency (CIA)\n",
      "- The Secret Service\n",
      "- The Postal Inspection Service\n",
      "- The Internal Revenue Service's Intelligence Division\n",
      "- The Treasury Department's Bureau of Alcohol, Tobacco, and Firearms\n",
      "\n",
      "However, little of consequence was discovered from these agencies.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sources:\n",
      "--------------------------------------------------------------------------------\n",
      "Source 1:\n",
      "  Text: Prefix: This FBI document about the investigation of Martin Luther King Jr.'s assassination describes the immediate police response and evidence colle...\n",
      "  Document: 66-me-2189_sec_001_ser_1-part_2_of_6.pdf\n",
      "  Page: 27\n",
      "\n",
      "Source 2:\n",
      "  Text: Prefix: This chunk appears in a January 1977 Department of Justice Task Force report reviewing FBI investigations of Martin Luther King Jr., specifica...\n",
      "  Document: 80-bf-2142_sec_000_ser_156-part_1_of_5.pdf\n",
      "  Page: 19\n",
      "\n",
      "Source 3:\n",
      "  Text: Prefix: This chunk from a 2025 government document about the MLK assassination investigation describes the initial police radio communications and evi...\n",
      "  Document: 80-bf-2142_sec_000_ser_156-part_2_of_5.pdf\n",
      "  Page: 6\n",
      "\n",
      "Source 4:\n",
      "  Text: Prefix: This chunk appears in a 1977 Department of Justice Task Force report reviewing the FBI's investigation of Martin Luther King Jr.'s assassinati...\n",
      "  Document: 80-ph-1591_sec_000_ser_138-part_1_of_5.pdf\n",
      "  Page: 19\n",
      "\n",
      "Source 5:\n",
      "  Text: Prefix: This chunk appears in a January 1977 Department of Justice Task Force report reviewing FBI investigations of Martin Luther King Jr., specifica...\n",
      "  Document: 62-hq-115768_sec_000_ser_262-part_1_of_5.pdf\n",
      "  Page: 19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 1: General information about the investigation\n",
    "ask_question(\"What agencies were involved in investigating Dr. King's assassination?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1610ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "--------------------------------------------------------------------------------\n",
      "The declassified records contain extensive information about James Earl Ray's criminal history, aliases, and his involvement in the assassination of Dr. Martin Luther King Jr. The records detail Ray's arrest history and aliases, including names such as James McBride, James Walton, W.C. Herron, and others. They document his progression through various jails and prisons for crimes including robbery, burglary, and forgery from 1949 to 1966. The records also highlight his conviction for the assassination of Martin Luther King Jr., for which he initially pleaded guilty and received a 99-year sentence, although he later recanted his confession and sought a trial. Additionally, the records include information about his escape from prison and his status as a fugitive before being captured.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sources:\n",
      "--------------------------------------------------------------------------------\n",
      "Source 1:\n",
      "  Text: Prefix: This chunk appears within an FBI criminal record document from 1977-1978 showing James Earl Ray's arrest history and aliases, which is part of...\n",
      "  Document: 44-kx-696_742347_02-02-part_3_of_3.pdf\n",
      "  Page: 17\n",
      "\n",
      "Source 2:\n",
      "  Text: Prefix: This chunk appears within an FBI record document dated April 23, 1968 (file #405 942 G) detailing James Earl Ray's criminal history and arrest...\n",
      "  Document: 44-al-493-493a_729423_02-02-part_1_of_6.pdf\n",
      "  Page: 10\n",
      "\n",
      "Source 3:\n",
      "  Text: Prefix: This chunk appears within an FBI criminal record report dated April 23, 1968 (document #405 942 G) detailing James Earl Ray's extensive arrest...\n",
      "  Document: 44-ls-947_sec_002_ser_76-200-part_6_of_8.pdf\n",
      "  Page: 25\n",
      "\n",
      "Source 4:\n",
      "  Text: Prefix: This FBI record from April 23, 1968 details James Earl Ray's criminal history and wanted status, appearing at the beginning of a larger collec...\n",
      "  Document: 44-mi-388_749561_06-02-part_2_of_8.pdf\n",
      "  Page: 1\n",
      "\n",
      "Source 5:\n",
      "  Text: Prefix: This chunk appears within an FBI criminal record report dated July 1968 detailing James Earl Ray's complete arrest history and prison transfer...\n",
      "  Document: 44-me-1987_hs1-852611265_86-02-part_1_of_3.pdf\n",
      "  Page: 41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Information about James Earl Ray\n",
    "ask_question(\"What information do the declassified records contain about James Earl Ray?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd74cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "--------------------------------------------------------------------------------\n",
      "On April 4, 1968, the timeline of events according to the declassified records is as follows:\n",
      "\n",
      "- **1:00 a.m.**: Mrs. Georgia M. Davis, Rev. A.D. Williams King (Dr. King's brother), and Mrs. Lucie Ward arrived in Memphis and registered at the Lorraine Motel. They were informed that Dr. King was attending a strategy meeting at a church.\n",
      "\n",
      "- **4:30 a.m.**: Dr. King, along with Reverends Ralph Abernathy and Bernard Lee, returned to the Lorraine Motel in a taxicab. Dr. King visited with his brother, Mrs. Davis, and Mrs. Ward in room 207 until about 5:00 a.m.\n",
      "\n",
      "- **5:00 a.m.**: Dr. King went to room 306, where he and Rev. Abernathy were registered. He later visited Mrs. Davis in room 201 for approximately one hour.\n",
      "\n",
      "- **8:00 a.m.**: Dr. King returned to room 306 for a strategy meeting.\n",
      "\n",
      "- **8:30 a.m.**: Solomon Jones, Jr., Dr. King's chauffeur, returned to the motel to take Dr. King to court. However, Rev. Andrew Young advised that he would go to court instead, so Jones remained at the motel.\n",
      "\n",
      "- **1:30 p.m.**: Dr. King returned to room 201 to visit Mrs. Davis. He was later joined by his brother, Mrs. Ward, Abernathy, Lee, Young, and Attorney Chauncey Eskridge.\n",
      "\n",
      "- **5:45 p.m.**: Dr. King announced they were going to dinner at the home of Rev. Billy Kyles. He saw Solomon Jones, Jr. in the motel courtyard and told him to start the car.\n",
      "\n",
      "- **6:00 p.m.**: Dr. King and Rev. Abernathy started to leave room 306. Dr. King walked out onto the balcony just outside the door to the room. He began a conversation with Jones about the weather. During this conversation, Dr. King was shot and fell to the floor of the balcony in front of room 306. Jones immediately called for help, and Dr. King's aides rushed to his side.\n",
      "\n",
      "This timeline outlines Dr. King's activities and movements on the day of his assassination.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sources:\n",
      "--------------------------------------------------------------------------------\n",
      "Source 1:\n",
      "  Text: Prefix: This chunk from a 1977 Department of Justice Task Force report on the FBI's investigation of Martin Luther King Jr.'s assassination provides a...\n",
      "  Document: 157-tp-3231_629182_176-02-part_2_of_6.pdf\n",
      "  Page: 8\n",
      "\n",
      "Source 2:\n",
      "  Text: Prefix: This chunk from a 1977 Department of Justice Task Force report reviewing the FBI's investigation of Martin Luther King Jr.'s assassination det...\n",
      "  Document: 44-om-310_763633_15-07-part_1_of_5.pdf\n",
      "  Page: 27\n",
      "\n",
      "Source 3:\n",
      "  Text: Prefix: This chunk from an FBI document about the investigation of Martin Luther King Jr.'s assassination describes the events of March 28, 1968 when ...\n",
      "  Document: 157-tp-3231_629182_176-02-part_2_of_6.pdf\n",
      "  Page: 4\n",
      "\n",
      "Source 4:\n",
      "  Text: Prefix: This chunk from a 1977 Department of Justice Task Force report on the FBI's Martin Luther King Jr. investigation describes the breakdown of Ki...\n",
      "  Document: 44-om-310_763633_15-07-part_1_of_5.pdf\n",
      "  Page: 23\n",
      "\n",
      "Source 5:\n",
      "  Text: Prefix: This chunk from a 1977 Department of Justice Task Force report on FBI investigations of MLK describes the events of March 28-29, 1968 in Memph...\n",
      "  Document: 80-bf-2142_sec_000_ser_156-part_1_of_5.pdf\n",
      "  Page: 27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Timeline of events\n",
    "ask_question(\"What was the timeline of events on April 4, 1968, according to the records?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9648b420",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've:\n",
    "\n",
    "1. Explored how the Unstructured platform processes historical documents through a sophisticated workflow\n",
    "2. Built a RAG application using LangChain to query the MLK assassination declassified records\n",
    "3. Demonstrated how these technologies can make important historical documents more accessible\n",
    "\n",
    "This approach can be applied to many other historical document collections, helping to preserve and make accessible our shared history.\n",
    "\n",
    "The combination of modern document processing, vector embeddings, and large language models creates powerful tools for researchers, educators, journalists, and the public to engage with historical materials in new and meaningful ways."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "mlk_scraper_env",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
