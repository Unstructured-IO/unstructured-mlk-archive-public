{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4594d62",
   "metadata": {},
   "source": [
    "# Making History Accessible: Exploring the MLK Assassination Declassified Records\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Dr. Martin Luther King Jr.'s legacy is one of courage, justice, and transformation. The recently declassified records surrounding his assassination (now hosted by the National Archives) are a vital part of the historical record. These documents provide important insights into a pivotal moment in American history and the civil rights movement.\n",
    "\n",
    "In this notebook, we'll explore how modern AI and data processing technologies can make these historical documents more accessible and searchable, enabling researchers, educators, journalists, and the public to engage with this important material.\n",
    "\n",
    "## Historical Context and Significance\n",
    "\n",
    "Dr. Martin Luther King Jr. was assassinated on April 4, 1968, in Memphis, Tennessee. His assassination had profound impacts on the civil rights movement and the nation as a whole.\n",
    "\n",
    "The declassified records surrounding his assassination provide valuable insights into:\n",
    "\n",
    "- The investigation conducted by various government agencies\n",
    "- The evidence collected and analyzed\n",
    "- The broader historical and social context of the time\n",
    "\n",
    "By making these records more accessible through modern AI and data processing technologies, we can help ensure that this important historical information is preserved and available for future generations to study and learn from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6280826",
   "metadata": {},
   "source": [
    "## The Unstructured Platform and Document Processing Workflow\n",
    "\n",
    "Before we build our question-answering application, let's understand the data processing workflow that makes this possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf490e2",
   "metadata": {},
   "source": [
    "### How the MLK Records Were Prepared for Search\n",
    "\n",
    "> *Note: The steps below were completed prior to this notebook. You do not need to rerun them—they’re included here to explain how the records were made searchable.*\n",
    "\n",
    "The declassified MLK assassination records were processed using the **Unstructured platform** in a multi-step ETL pipeline to make them AI-ready and searchable:\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 1: Document Ingestion into Amazon S3**\n",
    "\n",
    "- Original documents—including PDFs, images, and other file types—were streamed from the National Archives to **Amazon S3**, providing secure and scalable cloud storage.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 2: Document Processing with Unstructured**\n",
    "\n",
    "The Unstructured platform processed each document through a series of enrichment steps:\n",
    "\n",
    "1. **VLM Partitioning**  \n",
    "    Vision-Language Models (VLMs) segmented each document into meaningful sections, preserving layout and context. Because most documents were scanned images of typed pages—making OCR challenging—VLMs were chosen for partitioning.\n",
    "\n",
    "2. **Title-Based Chunking**  \n",
    "   Documents were split into semantically coherent chunks using structural cues (like section headers) to improve context retention.\n",
    "\n",
    "3. **Named Entity Recognition (NER)**  \n",
    "   Entities such as people, organizations, locations, and dates were extracted to enhance downstream filtering and relevance.\n",
    "\n",
    "4. **Vector Embedding**  \n",
    "   Each chunk was embedded using OpenAI’s `text-embedding-3-large` model (3072 dims), enabling semantic similarity search.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 3: Indexing in Elasticsearch**\n",
    "\n",
    "- The enriched document chunks—with metadata and vector embeddings—were indexed into **Elasticsearch**, enabling:\n",
    "  - Fast full-text and semantic (vector) search  \n",
    "  - Metadata-based filtering and sorting  \n",
    "  - Scalable querying across large document sets\n",
    "\n",
    "---\n",
    "\n",
    "This end-to-end pipeline transformed the raw historical documents into a searchable, structured knowledge base—optimized for natural language queries and intelligent retrieval. Unstructured made it possible to transform 243,496 pages of grainy text in a single day, with minimal engineering effort. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120f97ae",
   "metadata": {},
   "source": [
    "### Benefits of This Approach\n",
    "\n",
    "This workflow offers several advantages for historical document collections:\n",
    "\n",
    "- **Preservation of Context**: The intelligent partitioning and chunking preserve the document's original structure and context.\n",
    "\n",
    "- **Enhanced Searchability**: Both keyword and semantic search capabilities make it easier to find relevant information.\n",
    "\n",
    "- **Metadata Enrichment**: Named entity recognition adds valuable metadata that can be used for filtering and organization.\n",
    "\n",
    "- **Accessibility**: Makes historical documents more accessible to researchers, educators, and the public.\n",
    "\n",
    "- **AI-Readiness**: The processed data is ready for use in advanced AI applications, including RAG (Retrieval-Augmented Generation) systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea53bfbb",
   "metadata": {},
   "source": [
    "## Building a Question-Answering System for the MLK Assassination Records\n",
    "\n",
    "Now, let's build a Retrieval-Augmented Generation (RAG) application using LangChain that will allow us to query the ElasticSearch database to ask questions about the MLK assassination declassified records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a9cd86",
   "metadata": {},
   "source": [
    "### Setting Up the Environment\n",
    "\n",
    "First, let's install the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a66b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./mlk_scraper_env/lib/python3.13/site-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-elasticsearch in ./mlk_scraper_env/lib/python3.13/site-packages (0.3.2)\n",
      "Requirement already satisfied: langchain-openai in ./mlk_scraper_env/lib/python3.13/site-packages (0.3.28)\n",
      "Requirement already satisfied: langchain_anthropic in ./mlk_scraper_env/lib/python3.13/site-packages (0.3.17)\n",
      "Requirement already satisfied: python-dotenv in ./mlk_scraper_env/lib/python3.13/site-packages (1.1.1)\n",
      "Requirement already satisfied: elasticsearch in ./mlk_scraper_env/lib/python3.13/site-packages (8.18.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain) (0.3.71)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain) (0.4.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./mlk_scraper_env/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./mlk_scraper_env/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./mlk_scraper_env/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./mlk_scraper_env/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./mlk_scraper_env/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./mlk_scraper_env/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./mlk_scraper_env/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./mlk_scraper_env/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
      "Requirement already satisfied: elastic-transport<9,>=8.15.1 in ./mlk_scraper_env/lib/python3.13/site-packages (from elasticsearch) (8.17.1)\n",
      "Requirement already satisfied: python-dateutil in ./mlk_scraper_env/lib/python3.13/site-packages (from elasticsearch) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1 in ./mlk_scraper_env/lib/python3.13/site-packages (from elasticsearch[vectorstore-mmr]<9.0.0,>=8.13.1->langchain-elasticsearch) (2.3.1)\n",
      "Requirement already satisfied: simsimd>=3 in ./mlk_scraper_env/lib/python3.13/site-packages (from elasticsearch[vectorstore-mmr]<9.0.0,>=8.13.1->langchain-elasticsearch) (6.5.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain-openai) (1.97.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./mlk_scraper_env/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./mlk_scraper_env/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./mlk_scraper_env/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./mlk_scraper_env/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in ./mlk_scraper_env/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./mlk_scraper_env/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in ./mlk_scraper_env/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./mlk_scraper_env/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./mlk_scraper_env/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: anthropic<1,>=0.57.0 in ./mlk_scraper_env/lib/python3.13/site-packages (from langchain_anthropic) (0.58.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./mlk_scraper_env/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./mlk_scraper_env/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./mlk_scraper_env/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: six>=1.5 in ./mlk_scraper_env/lib/python3.13/site-packages (from python-dateutil->elasticsearch) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install langchain langchain-elasticsearch langchain-openai langchain_anthropic python-dotenv elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bf48df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377ad126",
   "metadata": {},
   "source": [
    "### Connecting to Elasticsearch\n",
    "\n",
    "We'll connect to the Elasticsearch instance where the processed MLK assassination records are stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d2768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elasticsearch connection settings\n",
    "ELASTICSEARCH_HOSTS = os.getenv(\"ELASTICSEARCH_HOSTS\", \"your-host-url\")\n",
    "ELASTICSEARCH_API_KEY = os.getenv(\"ELASTICSEARCH_API_KEY\", \"your-elasticsearch-api-key\")\n",
    "ELASTICSEARCH_INDEX_NAME = os.getenv(\"ELASTICSEARCH_INDEX_NAME\", \"mlk-archive-public\")\n",
    "\n",
    "# API key for OpenAI (used for both embeddings and LLM)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"your-openai-api-key\")\n",
    "\n",
    "from langchain_elasticsearch.vectorstores import ElasticsearchStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "# Correct parameter name is `es_api_key`\n",
    "es_store = ElasticsearchStore(\n",
    "    es_url=ELASTICSEARCH_HOSTS,\n",
    "    index_name=ELASTICSEARCH_INDEX_NAME,\n",
    "    es_api_key=ELASTICSEARCH_API_KEY,\n",
    "    embedding=embeddings,\n",
    "    vector_query_field=\"embeddings\",\n",
    "    query_field=\"text\",\n",
    ")\n",
    "\n",
    "\n",
    "# Create a retriever\n",
    "retriever = es_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}  # Retrieve top 5 most relevant documents\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28833aa4",
   "metadata": {},
   "source": [
    "### Creating a Prompt\n",
    "\n",
    "When dealing with sensitive historical material like the MLK assassination records, it's important to create a prompt that:\n",
    "\n",
    "1. Respects the historical significance of the material\n",
    "2. Provides accurate information based on the documents\n",
    "3. Acknowledges the limitations of the available information\n",
    "4. Avoids speculation beyond what's in the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a1b06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom prompt template\n",
    "template = \"\"\"\n",
    "You are a respectful and knowledgeable assistant helping to provide information about the declassified MLK assassination records.\n",
    "\n",
    "These documents are an important part of American history and the civil rights movement. Please treat this subject with the appropriate gravity and respect.\n",
    "\n",
    "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a65e104",
   "metadata": {},
   "source": [
    "### Building the RAG Application\n",
    "\n",
    "Now we'll create a Retrieval-Augmented Generation (RAG) application that:\n",
    "\n",
    "1. Takes a user question about the MLK assassination records\n",
    "2. Retrieves relevant document chunks from Elasticsearch\n",
    "3. Uses the retrieved context to generate an accurate, respectful answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff21ec1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OpenAI GPT-4o model for RAG responses\n"
     ]
    }
   ],
   "source": [
    "# Always use OpenAI for the LLM\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o\",\n",
    "    temperature=0.1,  # Low temperature for more factual responses\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")\n",
    "print(\"Using OpenAI GPT-4o model for RAG responses\")\n",
    "\n",
    "# Create the RAG chain\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT},\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590795e6",
   "metadata": {},
   "source": [
    "### Interactive Question Answering\n",
    "\n",
    "Let's create a simple interface to ask questions about the MLK assassination records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9657ea",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def ask_question(question):\n",
    "    \"\"\"\n",
    "    Ask a question about the MLK assassination records and get an answer\n",
    "    with source citations.\n",
    "    \"\"\"\n",
    "    result = rag_chain({\"query\": question})\n",
    "    \n",
    "    # Extract the answer and source documents\n",
    "    answer = result[\"result\"]\n",
    "    source_docs = result[\"source_documents\"]\n",
    "    \n",
    "    # Print the answer\n",
    "    print(\"Answer:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(answer)\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Print source information\n",
    "    print(\"\\nSources:\")\n",
    "    print(\"-\" * 80)\n",
    "    for i, doc in enumerate(source_docs):\n",
    "        print(f\"Source {i+1}:\")\n",
    "        print(f\"  Text: {doc.page_content[:150]}...\")\n",
    "        if hasattr(doc, 'metadata') and doc.metadata:\n",
    "            if 'filename' in doc.metadata:\n",
    "                print(f\"  Document: {doc.metadata['filename']}\")\n",
    "            if 'page_number' in doc.metadata:\n",
    "                print(f\"  Page: {doc.metadata['page_number']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2963d3d",
   "metadata": {},
   "source": [
    "### Example Questions\n",
    "\n",
    "Here are some example questions you might ask about the MLK assassination records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f21eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/1wcmv9gs233cdv2f_9tf246r0000gn/T/ipykernel_74021/1622397446.py:6: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = rag_chain({\"query\": question})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "--------------------------------------------------------------------------------\n",
      "The agencies involved in investigating Dr. Martin Luther King Jr.'s assassination were the Federal Bureau of Investigation (FBI) and the Department of Justice. Additionally, local law enforcement, such as the Memphis Police Department, was involved in the immediate response and evidence collection following the assassination.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sources:\n",
      "--------------------------------------------------------------------------------\n",
      "Source 1:\n",
      "  Text: Prefix: This chunk appears in the middle section of a December 1978 Summary of Findings and Recommendations report from the U.S. House Select Committe...\n",
      "  Document: 00387609_final_report_of_the_selec_104-10322-10090.pdf\n",
      "  Page: 10\n",
      "\n",
      "Source 2:\n",
      "  Text: Prefix: This chunk appears in the middle section of a 1979 House Select Committee on Assassinations report to Congress summarizing their findings and ...\n",
      "  Document: 00387464_letter_dear_mr_breckinri_104-10406-10387.pdf\n",
      "  Page: 9\n",
      "\n",
      "Source 3:\n",
      "  Text: Prefix: This chunk comes from a 1976 New York Times article examining whether the FBI was involved in Dr. Martin Luther King Jr.'s assassination, appe...\n",
      "  Document: 190-hq-709_bulky_231_sec_002_ser_231_only-part_01_of_10.pdf\n",
      "  Page: 44\n",
      "\n",
      "Source 4:\n",
      "  Text: Prefix: This excerpt from a Department of Justice report on the FBI investigation of Martin Luther King Jr.'s assassination describes the immediate po...\n",
      "  Document: 173-mx-1_sec_004_ser_366-part_2_of_5.pdf\n",
      "  Page: 1\n",
      "\n",
      "Source 5:\n",
      "  Text: Prefix: This chunk contains a newspaper article from the Times-Picayune (New Orleans) dated March 16, 1977 reporting on a Justice Department task forc...\n",
      "  Document: 157-no-10673_hs1-852666771_127-02-part_3_of_4.pdf\n",
      "  Page: 14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 1: General information about the investigation\n",
    "ask_question(\"What agencies were involved in investigating Dr. King's assassination?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11026cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "--------------------------------------------------------------------------------\n",
      "The declassified records contain several pieces of information about James Earl Ray, the assassin of Dr. Martin Luther King Jr. These records include:\n",
      "\n",
      "1. **CIA Memorandum (1975)**: This document indicates that the CIA conducted a file check on James Earl Ray in response to an inquiry from the Senate Select Committee. The file primarily consisted of news media material, State Department cables about his extradition from England, and memoranda regarding his first lawyer, Arthur J. Hanes. The CIA had no file on Ray prior to the assassination of Dr. King.\n",
      "\n",
      "2. **FBI Wanted Notice and Criminal Record (1968)**: This document details Ray's criminal history from 1953 to 1966, including arrests for robbery, burglary, larceny, forgery, and other charges. It also notes his addition to the FBI's \"Ten Most Wanted Fugitives\" list following the assassination.\n",
      "\n",
      "3. **CIA Document (1968)**: This document requests information about James Earl Ray, noting his birth date and place. It is part of the investigation into the assassination of Martin Luther King Jr.\n",
      "\n",
      "4. **Intelligence Document (1958)**: This document mentions Ray's arrest in London and questions why intelligence officials were not notified. It reflects operational intelligence matters during the Cold War.\n",
      "\n",
      "These records collectively provide insights into Ray's criminal background, the investigation following Dr. King's assassination, and the involvement of various government agencies in tracking and understanding Ray's activities.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sources:\n",
      "--------------------------------------------------------------------------------\n",
      "Source 1:\n",
      "  Text: Prefix: This is a complete CIA internal memorandum from December 12, 1975 documenting a file check on James Earl Ray (MLK's assassin) in response to a...\n",
      "  Document: 00490058_memo_re_james_earl_ray_5_104-10133-10386.pdf\n",
      "  Page: 1\n",
      "\n",
      "Source 2:\n",
      "  Text: Prefix: This chunk appears within an FBI wanted notice and criminal record document dated April 1968 for James Earl Ray (FBI #405942G), showing his ar...\n",
      "  Document: 157-sj-61_hs1-69642311_06-01-part_3_of_9.pdf\n",
      "  Page: 16\n",
      "\n",
      "Source 3:\n",
      "  Text: Prefix: This chunk appears within an FBI identification record document dated April 23, 1968 detailing James Earl Ray's criminal history and fingerpri...\n",
      "  Document: 157-bs-644_hs1-852666761_178-01-part_7_of_9.pdf\n",
      "  Page: 34\n",
      "\n",
      "Source 4:\n",
      "  Text: Prefix: This is a CIA document from April 26, 1968 requesting information about James Earl Ray, the suspected assassin of Martin Luther King Jr., whic...\n",
      "  Document: 00564571_cablereferences_are_reque_104-10433-10179.pdf\n",
      "  Page: 1\n",
      "\n",
      "Source 5:\n",
      "  Text: Prefix: This classified intelligence document from 1958 contains a message about James Earl Ray's arrest in London, sent between intelligence official...\n",
      "  Document: 06485443_ops_immediate_london_8_ju.pdf\n",
      "  Page: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Information about James Earl Ray\n",
    "ask_question(\"What information do the declassified records contain about James Earl Ray?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064e151f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "--------------------------------------------------------------------------------\n",
      "On April 4, 1968, the timeline of events according to the records is as follows:\n",
      "\n",
      "- **1:00 a.m.**: Dr. King's brother, Rev. A.D. King, along with Mrs. Georgia M. Davis and Mrs. Lucie Ward, arrived in Memphis and registered at the Lorraine Motel.\n",
      "\n",
      "- **4:30 a.m.**: Dr. King, along with Reverends Ralph Abernathy and Bernard Lee, returned to the Lorraine Motel from a strategy meeting and visited with his brother and others in room 207 until about 5:00 a.m.\n",
      "\n",
      "- **5:00 a.m.**: Dr. King returned to room 306, where he and Rev. Abernathy were registered.\n",
      "\n",
      "- **8:00 a.m.**: A strategy meeting was scheduled in room 306.\n",
      "\n",
      "- **8:30 a.m.**: Solomon Jones, Jr., Dr. King's chauffeur, returned to the Lorraine Motel to take Dr. King to court, but Rev. Andrew Young went instead.\n",
      "\n",
      "- **1:30 p.m.**: Dr. King visited Mrs. Davis in room 201 and was later joined by others, including his brother and SCLC staff.\n",
      "\n",
      "- **5:30 p.m.**: Dr. King and Rev. Abernathy returned to room 306 to get dressed for dinner at Rev. Billy Kyles' home.\n",
      "\n",
      "- **5:45 p.m.**: Dr. King announced they were going to dinner and began preparing to leave.\n",
      "\n",
      "- **6:00 p.m.**: Dr. King and Rev. Abernathy started to leave room 306. Dr. King walked onto the balcony outside the room and began a conversation with Solomon Jones, Jr., who was in the courtyard below. During this conversation, Dr. King was shot and fell to the floor of the balcony.\n",
      "\n",
      "These events outline Dr. King's activities and interactions leading up to his assassination on the balcony of the Lorraine Motel.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sources:\n",
      "--------------------------------------------------------------------------------\n",
      "Source 1:\n",
      "  Text: Prefix: This excerpt from a government document about Martin Luther King Jr.'s assassination describes the events between March 29-April 3, 1968, when...\n",
      "  Document: 07166993_hcsa_report_1976_1979_jfk.pdf\n",
      "  Page: 301\n",
      "\n",
      "Source 2:\n",
      "  Text: Prefix: This chunk from a 1977 Department of Justice Task Force report on the FBI's investigation of Martin Luther King Jr.'s assassination provides a...\n",
      "  Document: 157-tp-3231_629182_176-02-part_2_of_6.pdf\n",
      "  Page: 8\n",
      "\n",
      "Source 3:\n",
      "  Text: Prefix: This document details the civil rights movement and assassination of Dr. Martin Luther King Jr., and this chunk specifically describes King's ...\n",
      "  Document: 07166993_hcsa_report_1976_1979_jfk.pdf\n",
      "  Page: 302\n",
      "\n",
      "Source 4:\n",
      "  Text: Prefix: This chunk from an FBI document about the investigation of Martin Luther King Jr.'s assassination describes the events of March 28, 1968 when ...\n",
      "  Document: 157-tp-3231_629182_176-02-part_2_of_6.pdf\n",
      "  Page: 4\n",
      "\n",
      "Source 5:\n",
      "  Text: Prefix: This chunk from a 1977 Department of Justice Task Force report on the FBI's investigation of Martin Luther King Jr.'s assassination describes ...\n",
      "  Document: 173-mx-1_sec_004_ser_366-part_1_of_5.pdf\n",
      "  Page: 22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Timeline of events\n",
    "ask_question(\"What was the timeline of events on April 4, 1968, according to the records?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b5de3a",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've:\n",
    "\n",
    "1. Explored how the Unstructured platform processes historical documents through a sophisticated workflow\n",
    "2. Built a RAG application using LangChain to query the MLK assassination declassified records\n",
    "3. Demonstrated how these technologies can make important historical documents more accessible\n",
    "\n",
    "This approach can be applied to many other historical document collections, helping to preserve and make accessible our shared history.\n",
    "\n",
    "The combination of modern document processing, vector embeddings, and large language models creates powerful tools for researchers, educators, journalists, and the public to engage with historical materials in new and meaningful ways."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "mlk_scraper_env",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
